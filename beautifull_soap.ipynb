{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In summary, this code fetches the content of the \"page1.html\" webpage located at 'http://pythonscraping.com/pages/page1.html' and prints out the raw HTML content of that page. This is a basic example of web scraping, which is the process of programmatically extracting data from websites. Keep in mind that web scraping should be done responsibly and in accordance with the website's terms of use."
      ],
      "metadata": {
        "id": "IkZ-Qaz9M8Lb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6qShKLWYsCw",
        "outputId": "fb7129c9-4f37-4ed2-eb9f-ff75efbffbb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
          ]
        }
      ],
      "source": [
        "from urllib.request import urlopen\n",
        "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
        "print(html.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python code demonstrates web scraping using the `urllib` library to fetch and print the content of multiple webpages. It starts by importing the `urlopen` function from `urllib.request`. Next, a list of URLs is defined in the `urls` variable, containing three different webpage URLs. The code then enters a loop that iterates through each URL in the list. Inside the loop, the `urlopen` function is used to open each URL and retrieve its content. The content, obtained through `html.read()`, is then printed to the console along with the URL it came from. This process repeats for each URL in the list, effectively fetching and displaying the raw HTML content of the specified webpages. It's important to note that responsible web scraping practices, including adherence to website terms of use, should be followed when performing such operations."
      ],
      "metadata": {
        "id": "fjsAvtcCNTjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "\n",
        "# List of URLs\n",
        "urls = [\n",
        "    'http://pythonscraping.com/pages/page1.html',\n",
        "    'http://pythonscraping.com/pages/page2.html',\n",
        "    'http://pythonscraping.com/pages/page3.html'\n",
        "]\n",
        "\n",
        "# Loop through the URLs and fetch their content\n",
        "for url in urls:\n",
        "    html = urlopen(url)\n",
        "    print(f\"Content from {url}:\\n{html.read()}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bED0JWscotp",
        "outputId": "5e3b89cf-f171-4120-9ba2-abe05d2576a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content from http://pythonscraping.com/pages/page1.html:\n",
            "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n",
            "\n",
            "Content from http://pythonscraping.com/pages/page2.html:\n",
            "b'\\n<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div class=\"body\" id=\"fakeLatin\">\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n",
            "\n",
            "Content from http://pythonscraping.com/pages/page3.html:\n",
            "b'<html>\\n<head>\\n<style>\\nimg{\\n\\twidth:75px;\\n}\\ntable{\\n\\twidth:50%;\\n}\\ntd{\\n\\tmargin:10px;\\n\\tpadding:10px;\\n}\\n.wrapper{\\n\\twidth:800px;\\n}\\n.excitingNote{\\n\\tfont-style:italic;\\n\\tfont-weight:bold;\\n}\\n</style>\\n</head>\\n<body>\\n<div id=\"wrapper\">\\n<img src=\"../img/gifts/logo.jpg\" style=\"float:left;\">\\n<h1>Totally Normal Gifts</h1>\\n<div id=\"content\">Here is a collection of totally normal, totally reasonable gifts that your friends are sure to love! Our collection is\\nhand-curated by well-paid, free-range Tibetan monks.<p>\\nWe haven\\'t figured out how to make online shopping carts yet, but you can send us a check to:<br>\\n123 Main St.<br>\\nAbuja, Nigeria\\n</br>We will then send your totally amazing gift, pronto! Please include an extra $5.00 for gift wrapping.</div>\\n<table id=\"giftList\">\\n<tr><th>\\nItem Title\\n</th><th>\\nDescription\\n</th><th>\\nCost\\n</th><th>\\nImage\\n</th></tr>\\n\\n<tr id=\"gift1\" class=\"gift\"><td>\\nVegetable Basket\\n</td><td>\\nThis vegetable basket is the perfect gift for your health conscious (or overweight) friends!\\n<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\\n</td><td>\\n$15.00\\n</td><td>\\n<img src=\"../img/gifts/img1.jpg\">\\n</td></tr>\\n\\n<tr id=\"gift2\" class=\"gift\"><td>\\nRussian Nesting Dolls\\n</td><td>\\nHand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\\n</td><td>\\n$10,000.52\\n</td><td>\\n<img src=\"../img/gifts/img2.jpg\">\\n</td></tr>\\n\\n<tr id=\"gift3\" class=\"gift\"><td>\\nFish Painting\\n</td><td>\\nIf something seems fishy about this painting, it\\'s because it\\'s a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\\n</td><td>\\n$10,005.00\\n</td><td>\\n<img src=\"../img/gifts/img3.jpg\">\\n</td></tr>\\n\\n<tr id=\"gift4\" class=\"gift\"><td>\\nDead Parrot\\n</td><td>\\nThis is an ex-parrot! <span class=\"excitingNote\">Or maybe he\\'s only resting?</span>\\n</td><td>\\n$0.50\\n</td><td>\\n<img src=\"../img/gifts/img4.jpg\">\\n</td></tr>\\n\\n<tr id=\"gift5\" class=\"gift\"><td>\\nMystery Box\\n</td><td>\\nIf you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\\n</td><td>\\n$1.50\\n</td><td>\\n<img src=\"../img/gifts/img6.jpg\">\\n</td></tr>\\n</table>\\n</p>\\n<div id=\"footer\">\\n&copy; Totally Normal Gifts, Inc. <br>\\n+234 (617) 863-0736\\n</div>\\n\\n</div>\\n</body>\\n</html>\\n'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet utilizes the `urllib` library to open a webpage at 'http://www.pythonscraping.com/pages/page1.html'. It then imports the `BeautifulSoup` class from the `bs4` (Beautiful Soup 4) library, which is commonly used for parsing and navigating HTML content. The `urlopen` function fetches the webpage's content, and the `BeautifulSoup` constructor is used to create a Beautiful Soup object called `bs`, which represents the parsed HTML content. Finally, the code prints out the content enclosed within the first `<h1>` (heading level 1) tag of the webpage. In essence, this code fetches the content of the specified webpage, parses it, and extracts and prints the content of the first main heading on the page."
      ],
      "metadata": {
        "id": "1tWZk3GLNsfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
        "bs = BeautifulSoup(html.read(), 'html.parser')\n",
        "print(bs.h1)\n"
      ],
      "metadata": {
        "id": "9ee3v0-_wL_j",
        "outputId": "ca987e0c-bd1d-475a-8e93-c5266da1b5b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<h1>An Interesting Title</h1>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code segment imports the `BeautifulSoup` class from the `bs4` library and the `urlopen` function from `urllib.request`. It then uses the `urlopen` function to retrieve the HTML content of the webpage located at 'http://pythonscraping.com/pages/page1.html'. However, the variable `bs` is not defined before attempting to print it, which would result in an error. To clarify, the `BeautifulSoup` object should be created from the fetched HTML content using the line `bs = BeautifulSoup(html.read(), 'html.parser')` before attempting to print it. The `BeautifulSoup` object represents the parsed HTML content and provides methods to navigate and extract information from the page's structure."
      ],
      "metadata": {
        "id": "u7F-1Q8WOCJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n",
        "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
        "print(bs)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HsD0pZ0Lfc8",
        "outputId": "f3ecff6c-3d40-422d-8661-8540d1f15f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html>\n",
            "<head>\n",
            "<title>A Useful Page</title>\n",
            "</head>\n",
            "<body>\n",
            "<h1>An Interesting Title</h1>\n",
            "<div>\n",
            "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
            "</div>\n",
            "</body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a Python function named `getTitle` that takes a URL as its argument. It utilizes the `urlopen` function from the `urllib.request` module to fetch the HTML content from the provided URL. If an HTTP error occurs during the request, it returns `None`. Then, it uses BeautifulSoup to parse the HTML and searches for the first `<h1>` tag within the `<body>` of the HTML content. If the tag is not found, it returns `None`. The function returns the found `<h1>` tag. The code then calls this function with a specific URL and assigns the returned result to the variable `title`. If the `title` is `None`, it prints 'Not found topic'. Otherwise, it prints the content of the `title` variable. This code demonstrates how to handle HTTP errors, parse HTML content, and extract information using BeautifulSoup in a web scraping context."
      ],
      "metadata": {
        "id": "ORBH6F9ROdjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "from urllib.error import HTTPError\n",
        "from bs4 import BeautifulSoup\n",
        "def getTitle(url):\n",
        "    try:\n",
        "        html = urlopen(url)\n",
        "    except HTTPError as e:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        bs = BeautifulSoup(html.read(), 'html.parser')\n",
        "        title = bs.body.h1\n",
        "    except AttributeError as e:\n",
        "        return None\n",
        "\n",
        "    return title\n",
        "\n",
        "title = getTitle('http://www.pythonscraping.com/pages/page1.html')\n",
        "\n",
        "if title == None:\n",
        "    print('Not found topic')\n",
        "else:\n",
        "    print(title)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_LKK0yCBdHl",
        "outputId": "ea42d3c8-bcf6-4951-9e52-4caf407018fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<h1>An Interesting Title</h1>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a function named `getTitle` that attempts to fetch a webpage's HTML content using the `urlopen` function from the `urllib.request` module. If an HTTP error occurs during the request, the function returns `None`. It then uses BeautifulSoup to parse the HTML and searches for the first `<h1>` tag within the `<body>` section. If the tag is not found, the function returns `None`. The code then calls the `getTitle` function with a specific URL and stores the result in the variable `title`. If `title` is `None`, it prints 'Not found'. Otherwise, it prints the content of the `title` variable. This code demonstrates error handling and HTML parsing with BeautifulSoup for extracting specific information from a web page."
      ],
      "metadata": {
        "id": "lBteqjrXOj-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "from urllib.error import HTTPError\n",
        "from bs4 import BeautifulSoup\n",
        "def getTitle(url):\n",
        "    try:\n",
        "        html = urlopen(url)\n",
        "    except HTTPError as e:\n",
        "\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        bs = BeautifulSoup(html.read(), 'html.parser')\n",
        "        title = bs.body.h1\n",
        "    except AttributeError as e:\n",
        "        return None\n",
        "\n",
        "    return title\n",
        "\n",
        "title = getTitle('http://www.pythonscraping.com/pages/page1.html')\n",
        "\n",
        "if title == None:\n",
        "    print('Not found)\n",
        "else:\n",
        "    print(title)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k__zji0TK5F0",
        "outputId": "5a31053d-ac96-4d20-c121-9b896ae885a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<h1>An Interesting Title</h1>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code imports necessary modules and uses `urlopen` to fetch the HTML content from a webpage. It then utilizes BeautifulSoup to parse the HTML using the specified parser. The code loops through the children of a table with the `id` attribute 'giftList'. For each child, it prints the HTML content, effectively extracting and displaying the information within the specified table. This code demonstrates how to access and manipulate the structure of HTML elements within a specific section of a webpage using BeautifulSoup."
      ],
      "metadata": {
        "id": "FqPD_jbLO9fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "html = urlopen('http://www.pythonscraping.com/pages/page3.html')\n",
        "bs = BeautifulSoup(html, 'html.parser')\n",
        "for child in bs.find('table',{'id':'giftList'}).children:\n",
        "    print(child)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPTGqn8zcrbW",
        "outputId": "5e08b730-a5c2-48b8-cba7-7591b16c4f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "<tr><th>\n",
            "Item Title\n",
            "</th><th>\n",
            "Description\n",
            "</th><th>\n",
            "Cost\n",
            "</th><th>\n",
            "Image\n",
            "</th></tr>\n",
            "\n",
            "\n",
            "<tr class=\"gift\" id=\"gift1\"><td>\n",
            "Vegetable Basket\n",
            "</td><td>\n",
            "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
            "<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
            "</td><td>\n",
            "$15.00\n",
            "</td><td>\n",
            "<img src=\"../img/gifts/img1.jpg\"/>\n",
            "</td></tr>\n",
            "\n",
            "\n",
            "<tr class=\"gift\" id=\"gift2\"><td>\n",
            "Russian Nesting Dolls\n",
            "</td><td>\n",
            "Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
            "</td><td>\n",
            "$10,000.52\n",
            "</td><td>\n",
            "<img src=\"../img/gifts/img2.jpg\"/>\n",
            "</td></tr>\n",
            "\n",
            "\n",
            "<tr class=\"gift\" id=\"gift3\"><td>\n",
            "Fish Painting\n",
            "</td><td>\n",
            "If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
            "</td><td>\n",
            "$10,005.00\n",
            "</td><td>\n",
            "<img src=\"../img/gifts/img3.jpg\"/>\n",
            "</td></tr>\n",
            "\n",
            "\n",
            "<tr class=\"gift\" id=\"gift4\"><td>\n",
            "Dead Parrot\n",
            "</td><td>\n",
            "This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
            "</td><td>\n",
            "$0.50\n",
            "</td><td>\n",
            "<img src=\"../img/gifts/img4.jpg\"/>\n",
            "</td></tr>\n",
            "\n",
            "\n",
            "<tr class=\"gift\" id=\"gift5\"><td>\n",
            "Mystery Box\n",
            "</td><td>\n",
            "If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
            "</td><td>\n",
            "$1.50\n",
            "</td><td>\n",
            "<img src=\"../img/gifts/img6.jpg\"/>\n",
            "</td></tr>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code uses the BeautifulSoup library in Python to illustrate how to navigate and extract information from HTML elements. It begins by defining an HTML string representing a webpage with nested `<div>` elements. The code then creates a BeautifulSoup object to parse this HTML. It finds the parent element with the ID 'parent' and subsequently locates all child elements within it that have the class 'child'. The content of these child elements is displayed using a loop. It also demonstrates finding the parent of one of the child elements and displays its content. Lastly, the code finds the siblings of the first child element and displays their content as well. Overall, this example demonstrates how BeautifulSoup can be used to traverse and manipulate HTML elements efficiently."
      ],
      "metadata": {
        "id": "grF47CGuPMOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#Suppose html_str is the HTML text of the web page you want\n",
        "html_str = \"\"\"\n",
        "<html>\n",
        "  <body>\n",
        "    <div id=\"parent\">\n",
        "      <div class=\"child\">First Child</div>\n",
        "      <div class=\"child\">Second Child</div>\n",
        "      <div class=\"child\">Third Child</div>\n",
        "    </div>\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Create a Beautiful Soup object using HTML text\n",
        "soup = BeautifulSoup(html_str, 'html.parser')\n",
        "\n",
        "# Find the parent element\n",
        "parent_element = soup.find('div', id='parent')\n",
        "\n",
        "# Find all child elements\n",
        "child_elements = parent_element.find_all('div', class_='child')\n",
        "\n",
        "# Display the content of child elements\n",
        "for child in child_elements:\n",
        "    print(child.text)\n",
        "\n",
        "# Find parent element based on child elements\n",
        "parent_of_children = child_elements[0].find_parent()\n",
        "\n",
        "# Display the content of the parent element\n",
        "print(parent_of_children.text)\n",
        "\n",
        "# Find siblings of an element\n",
        "sibling_elements = child_elements[0].find_next_siblings()\n",
        "\n",
        "# Show content of sisters/brothers\n",
        "for sibling in sibling_elements:\n",
        "    print(sibling.text)\n"
      ],
      "metadata": {
        "id": "_FTJhFlROb5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3707ab9-4f7b-4d8f-9b57-c613daab79d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Child\n",
            "Second Child\n",
            "Third Child\n",
            "\n",
            "First Child\n",
            "Second Child\n",
            "Third Child\n",
            "\n",
            "Second Child\n",
            "Third Child\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet demonstrates how to utilize the BeautifulSoup library in Python to parse HTML content and extract specific elements. It starts by defining an HTML content string and then uses BeautifulSoup to parse it. The code employs the `find_all` method to locate all anchor ('a') tags within the parsed HTML and subsequently prints the value of their href attributes. Additionally, it employs the `find` method to extract the text content of the first paragraph ('p') tag and prints it. This example showcases how BeautifulSoup simplifies the process of navigating and extracting data from HTML documents."
      ],
      "metadata": {
        "id": "a-FfhwcC4w-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# HTML content to parse\n",
        "html_content = \"\"\"\n",
        "<html>\n",
        "   <body>\n",
        "       <h1>Welcome to my website</h1>\n",
        "       <p>This is a paragraph.</p>\n",
        "       <a href=\"https://www.example.com\">Visit Example</a>\n",
        "   </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Parse the HTML content\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Using find_all to extract all 'a' tags\n",
        "all_links = soup.find_all('a')\n",
        "for link in all_links:\n",
        "   print(link['href'])  # Print the href attribute of each link\n",
        "\n",
        "# Using find to extract the first 'p' tag\n",
        "first_paragraph = soup.find('p').text\n",
        "print(first_paragraph)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSCaEc5wdOTD",
        "outputId": "440084de-104a-4bbc-955c-cd622d6a6e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.example.com\n",
            "This is a paragraph.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet illustrates how to use the BeautifulSoup library in Python to parse HTML content and extract specific elements. It demonstrates two scenarios: first, it finds all anchor ('a') tags with a specific href attribute value ('https://www.example.com') and prints their text content. Second, it searches for the first anchor tag with a specific CSS class ('special-link') and prints its href attribute value. This showcases the library's ability to locate and extract elements based on attributes and classes within HTML content."
      ],
      "metadata": {
        "id": "-RTD3FIS5L4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Your HTML content here\n",
        "html_content = \"\"\"\n",
        "<html>\n",
        "   <body>\n",
        "       <h1>Welcome to my website</h1>\n",
        "       <p>This is a paragraph.</p>\n",
        "       <a href=\"https://www.example.com\">Visit Example</a>\n",
        "   </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Using find_all to search for tags with specific attributes\n",
        "specific_links = soup.find_all('a', href='https://www.example.com')\n",
        "for link in specific_links:\n",
        "    print(link.text)\n",
        "\n",
        "# Using find to search for the first 'a' tag with a specific class\n",
        "specific_link = soup.find('a', class_='special-link')\n",
        "if specific_link is not None:\n",
        "    print(specific_link['href'])\n",
        "else:\n",
        "    print(\"No link with class 'special-link' found.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqL1gsC3d_QK",
        "outputId": "88aadf4f-e461-4ec1-f434-bf73bbc0bbd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visit Example\n",
            "No link with class 'special-link' found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet showcases the navigation functionalities of the BeautifulSoup library in Python for HTML parsing. It begins by using `soup.find('p')` to locate a 'p' tag (paragraph) within the parsed HTML content. The code then prints the text content of the paragraph using `paragraph.text`. Next, it retrieves the name of the parent tag of the paragraph using `paragraph.parent.name` and prints it. The code utilizes a loop to iterate through the children of the paragraph, displaying each child's content using `print(child)`. Additionally, it demonstrates the ability to navigate through siblings of the paragraph. It employs `paragraph.find_next_sibling('p')` to find the next 'p' tag and `paragraph.find_previous_sibling('p')` to locate the previous 'p' tag. This code exemplifies how to traverse and manipulate the hierarchical structure of HTML elements using BeautifulSoup's navigation methods."
      ],
      "metadata": {
        "id": "k8R7gRKt5mpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigating through parent, children, and siblings\n",
        "paragraph = soup.find('p')\n",
        "print(paragraph.text)\n",
        "print(paragraph.parent.name)  # Print the parent tag's name\n",
        "\n",
        "for child in paragraph.children:\n",
        "   print(child)\n",
        "\n",
        "# Navigating through siblings\n",
        "next_sibling = paragraph.find_next_sibling('p')\n",
        "previous_sibling = paragraph.find_previous_sibling('p')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY01KAL8e_aa",
        "outputId": "ab483adf-cb05-40ba-c68f-077f2210471e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a paragraph.\n",
            "body\n",
            "This is a paragraph.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet demonstrates how to utilize the BeautifulSoup library in Python to parse HTML content. It begins by importing the library and providing HTML content as a string. The code then initializes a BeautifulSoup object to parse the HTML. It showcases the concept of navigating through the ancestor elements of a specific 'a' tag (hyperlink) and displays their tag names. Additionally, it illustrates how to traverse through the descendants of the 'body' tag, printing the names of non-empty descendant tags. Finally, the code finds all the text content within the 'a' tag and its descendants, providing a useful technique for text extraction from HTML elements. This example highlights the capabilities of BeautifulSoup for HTML parsing and navigation tasks."
      ],
      "metadata": {
        "id": "8Xk-jS8J52Nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Your HTML content here\n",
        "html_content = \"\"\"\n",
        "<html>\n",
        "   <body>\n",
        "       <h1>Welcome to my website</h1>\n",
        "       <p>This is a paragraph.</p>\n",
        "       <a href=\"https://www.example.com\">Visit Example</a>\n",
        "   </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Navigating through ancestors\n",
        "link = soup.find('a')\n",
        "ancestors = link.find_parents()\n",
        "for ancestor in ancestors:\n",
        "    print(ancestor.name)\n",
        "\n",
        "# Navigating through descendants\n",
        "descendants = soup.find('body').descendants\n",
        "for descendant in descendants:\n",
        "    if descendant.name is not None:\n",
        "        print(descendant.name)\n",
        "\n",
        "# Searching for all text within a tag and its descendants\n",
        "all_text = link.find_all(text=True)\n",
        "print(all_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT_tJXLLlPjt",
        "outputId": "24545994-6ca4-407e-ded1-25cf210e7703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "body\n",
            "html\n",
            "[document]\n",
            "h1\n",
            "p\n",
            "a\n",
            "['Visit Example']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-e75ff11cb673>:29: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  all_text = link.find_all(text=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet utilizes the BeautifulSoup library to parse HTML content. It first locates an 'a' tag (hyperlink) and finds its ancestor tags, demonstrating the upward navigation. It also shows how to traverse through descendants of the 'body' tag, highlighting the hierarchical structure of HTML elements. Additionally, the code extracts all text content within a specified tag and its descendants. This example underscores how BeautifulSoup simplifies HTML navigation and extraction tasks in Python."
      ],
      "metadata": {
        "id": "NaVehwTS6IPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Your HTML content here\n",
        "html_content = \"\"\"\n",
        "<html>\n",
        "   <body>\n",
        "       <h1>Welcome to my website</h1>\n",
        "       <p>This is a paragraph.</p>\n",
        "       <a href=\"https://www.example.com\">Visit Example</a>\n",
        "   </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Navigating through ancestors\n",
        "link = soup.find('a')\n",
        "ancestors = link.find_parents()\n",
        "for ancestor in ancestors:\n",
        "    print(ancestor.name)\n",
        "\n",
        "# Navigating through descendants\n",
        "descendants = soup.find('body').descendants\n",
        "for descendant in descendants:\n",
        "    if descendant.name is not None:\n",
        "        print(descendant.name)\n",
        "\n",
        "# Searching for all text within a tag and its descendants\n",
        "all_text = link.find_all(text=True)\n",
        "print(all_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i90p8CX2xjKI",
        "outputId": "9e2757f6-3d6d-45b3-81c6-98b473628185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "body\n",
            "html\n",
            "[document]\n",
            "h1\n",
            "p\n",
            "a\n",
            "['Visit Example']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-3f4ea30ce3cb>:29: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  all_text = link.find_all(text=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tkvqDUkWxfx5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}